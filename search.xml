<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>记撸一个双链表快排</title>
      <link href="2021/06/23/%E8%AE%B0%E6%92%B8%E4%B8%80%E4%B8%AA%E5%8F%8C%E9%93%BE%E8%A1%A8%E5%BF%AB%E6%8E%92/"/>
      <url>2021/06/23/%E8%AE%B0%E6%92%B8%E4%B8%80%E4%B8%AA%E5%8F%8C%E9%93%BE%E8%A1%A8%E5%BF%AB%E6%8E%92/</url>
      
        <content type="html"><![CDATA[<p>刷面筋的时候看到有问双链表排序问题。</p><p>正想着用快排怎么排序双链表，写的时候各种空指针。写完后顺便记录一下爬坑过程吧。</p><p>双链表的结构体构思很简单。一开始就简单构造了一下，没想别的。</p><pre><code>type dLinkedList struct &#123;    Data  int    Prev  *dLinkedList    Next  *dLinkedList&#125;</code></pre><p>顺便写一下构造函数，包括随机数的生成呀，什么的。因为建链表的时候不想把for循环拆开讨论，直接建了一个前置节点，只要后面销毁就好了。顺便写好打印函数，测试一下。双链表就这么构造好了，一切都很顺利。</p><pre><code>func NewNode(x int) *dLinkedList &#123;    return &amp;dLinkedList&#123;        Data:  x,    &#125;&#125;func (d *dLinkedList) AddNode(x) &#123;    node := NewNode(x)    d.Next = node    node.Prev = d&#125;func (d *dLinkedList) Print() &#123;    cur := d    for cur != nil &#123;        fmt.Printf(&quot;%d &quot;, cur.Data)        cur = cur.Next    &#125;    fmt.Println()&#125;func GenDLL(size, min, max int) *dLinkedList &#123;    nums := Generate(size, min, max)    head := NewNode(0)    cur := head    for i := 0; i &lt; len(nums); i++ &#123;        cur.AddNode(nums[i])        cur = cur.Next    &#125;    head = head.Next    head.Prev = nil    return head&#125;</code></pre><p>数组的快排非常简单，分治的思想，首尾指针不断向中心移动，和 <code>pivot</code> 对比决定是否交换。</p><p>到了链表这里，一些细节就需要处理，比如，首尾指针怎么判断是否相交？pivot 取哪个？</p><p>懒人总是想用莫名奇妙的方法去实现，明明知道它不合理，但不想修改原来的代码，就算只是加个索引，这么简单的事情也懒得去做。（我也是服了自己了）。为了不想修改原先的代码，判断首尾指针相交，我只是简单比较了两个节点是否相等，并考虑到两个节点错位一格的情况，实际细想，也有错位两格的特殊情况。</p><p>果然，这种脆弱的代码根本不会给我老老实实排好序，因为我就算解决了首尾指针相交的问题，在进入递归的部分，选取递归范围又犯了难，不使用索引来判断范围是否合法是不简单的事情，当然可以写一个函数来判断范围是否合法，但是链表的遍历是非常耗费时间的事情。增加时间复杂度很显然不应该去做。最后，还是老老实实给每一个节点增加了索引。</p><p>接着就是 pivot 的选取了。</p><p>最开始学的算法书写的 pivot 取数组第一个值就可以了。当然这在数组里倒是没什么问题，到了链表，就会出现空指针引用的问题。当然，没有思考这是为什么，只是简单的把 pivot 换成了链表中心的值，我只是希望 pivot 尽可能不要跑到两边的位置。</p><p>要在脑子里模拟快排的每一步细节是很吃力的事情，天生犯懒的我也就这样过了。</p><p>最后就是<a href="https://github.com/Jiaget/notes/blob/main/algorithm/d-linked-list.go">双向链表的代码了</a></p><p>唉，算法苦手~</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 双链表 </tag>
            
            <tag> 快排 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Golang之反射</title>
      <link href="2021/06/23/Golang%E4%B9%8B%E5%8F%8D%E5%B0%84/"/>
      <url>2021/06/23/Golang%E4%B9%8B%E5%8F%8D%E5%B0%84/</url>
      
        <content type="html"><![CDATA[<p>反射的作用只是将类型元数据返回给用户。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 类型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>窥探Gin框架</title>
      <link href="2021/06/20/%E7%AA%A5%E6%8E%A2Gin%E6%A1%86%E6%9E%B6/"/>
      <url>2021/06/20/%E7%AA%A5%E6%8E%A2Gin%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<p>几个月前，为了学习Gin框架的基本使用（实际还有许多Golang其他的工具框架），从头搭建了一个简易的客户端服务端 – <img src="https://github.com/Jiaget/simplebank" alt="一个简易的银行系统"></p><p>作为练手项目，Gin有很多特性与功能都没有研究与使用过， 这次的学习希望可以从深度和广度两个方面，更加全面的一窥Gin框架，这个活跃在社区广受好评的web框架。</p><h1 id="回顾-HTTP-服务开发的基本流程"><a href="#回顾-HTTP-服务开发的基本流程" class="headerlink" title="回顾 HTTP 服务开发的基本流程"></a>回顾 HTTP 服务开发的基本流程</h1><ul><li>开启TCP 监听</li><li>初始化一些 <code>handler</code> 处理具体的业务逻辑</li><li>将业务逻辑和相关的 <code>Method</code>, <code>URL</code> 绑定，对外暴露一些具体功能服务</li></ul><h1 id="Gin-的几个重要模型："><a href="#Gin-的几个重要模型：" class="headerlink" title="Gin 的几个重要模型："></a>Gin 的几个重要模型：</h1><ul><li><p>Engine </p><ul><li>初始化一个 <code>gin</code> 对象实例，该对象实例中包含一些框架的基础功能， <code>日志</code>, <code>中间件设置</code>, <code>路由控制</code>, <code>handlercontext</code></li></ul></li><li><p>Router:</p><ul><li>定义路由规则与条件，通过HTTP服务将具体路由注册到一个 <code>context</code> 实现的Handler 中</li></ul></li><li><p>Context:</p><ul><li>该模块是框架中重要的一环，它可以让我们在中间件中共享变量，管理整个流程，验证请求的json， 提供一个json的响应。</li></ul></li><li><p>Bind:</p><ul><li>context 中，可以获取到请求的详细信息（ HTTP 的 head 和 body）</li><li>但是我们需要根据不同的HTTP协议参数获取相应的格式化数据，来处理底层的业务逻辑，这需要我们使用 <code>bind</code> 相关的方法来解析 HTTP数据。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Gin </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> Web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式</title>
      <link href="2021/06/19/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>2021/06/19/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>简述一下各个设计模式，顺便用Golang实现。</p><h1 id="创建型模式"><a href="#创建型模式" class="headerlink" title="创建型模式"></a>创建型模式</h1><h2 id="简单工厂模式"><a href="#简单工厂模式" class="headerlink" title="简单工厂模式"></a>简单工厂模式</h2><p>根据参数的不同，返回不同类的实例。简单工厂模式定义一个类来负责创建其他类的实例。</p><p>Golang的设计理念弱化了面向对象的概念，它没有构造函数的概念，但规范化的代码会使用Newxx的函数来初始化类。</p><h3 id="简单工厂的优点"><a href="#简单工厂的优点" class="headerlink" title="简单工厂的优点"></a>简单工厂的优点</h3><ul><li>客户端不需要直接创建对象实例，会有专门的工厂类用于这类工作</li><li>换句话说，客户端无需知道产品类的类名，只需要知道对应参数，而对应参数名的命名只需要规范，易读</li><li>可以引入配置文件，在不修改代码的情况下更改产品类。</li></ul><h3 id="简单工厂的缺点"><a href="#简单工厂的缺点" class="headerlink" title="简单工厂的缺点"></a>简单工厂的缺点</h3><ul><li>工厂类担负的责任过重，一旦不能工作，整个系统都会被影响</li><li>增加了系统类的个数，复杂度增加（虽然在工厂模式中是简单的实现）</li><li>扩展困难，增加新的产品类，就要修改工厂逻辑</li></ul><p><img src="https://github.com/Jiaget/notes/blob/main/patterns/simple/simple.go" alt="简单工厂demo"></p><h2 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h2><p>简单方法模式将代码逻辑压力集中在了一个工厂类上面，工厂方法模式显然希望缓解工厂类的压力而设计出来的。</p><p>我们会先定义一个抽象工厂类，再定义具体的工厂类来实现不同的产品。这种模式下，当出现新的产品，只需要为这个产品创建一个具体的工厂类即可获取新的实例。</p><p><img src="https://github.com/Jiaget/notes/blob/main/patterns/factory_method/factory_method.go" alt="工厂方法demo"></p><h3 id="工厂方法优点"><a href="#工厂方法优点" class="headerlink" title="工厂方法优点"></a>工厂方法优点</h3><ul><li>工厂方法模式中，工厂方法创建产品，并隐藏产品类将被实例化的细节。只需关系产品对应的工厂，无需知道类名。</li><li>多态，可以使工厂自主确定创建何种产品。所有的具体工厂都有同一个抽象的父类。（Golang实现继承需要通过接口的特性，使用组合来实现。）</li></ul>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GC(二)</title>
      <link href="2021/06/18/golang%E7%9A%84GC-%E4%BA%8C/"/>
      <url>2021/06/18/golang%E7%9A%84GC-%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<p>之前，主要讲了golang的三色标记法以及混合写屏障机制。这里简略介绍一下一些GC机制。</p><h2 id="简述三色标记法"><a href="#简述三色标记法" class="headerlink" title="简述三色标记法"></a>简述三色标记法</h2><p>三色标记法是一种追踪式回收机制：</p><ul><li>垃圾回收开始时：所有数据标记为白色</li><li>将可以追踪到的root节点标记为灰色（灰色表示由当前节点展开的追踪还未完成）</li><li>当该节点追踪任务完成，该节点标记为黑色，并无需再次基于它展开追踪</li><li>由黑色节点追踪到的节点会被标记为灰色。</li><li>当所有的灰色节点都被标记为黑色时，标记工作完成</li><li>白色节点均为垃圾</li></ul><h2 id="标记清除带来的问题"><a href="#标记清除带来的问题" class="headerlink" title="标记清除带来的问题"></a>标记清除带来的问题</h2><p>内存碎片化，回收的内存很难保证能成片聚在一起。而这些小块内存碎片会导致找出合适的内存空间进行分配的工作将付出更高的代价。甚至一些小块内存永远无法使用</p><h3 id="Bibop"><a href="#Bibop" class="headerlink" title="Bibop"></a>Bibop</h3><p>这是一种管理碎片化内存的机制，它将大小规格相同的内存碎片统一管理。从而快速匹配内存。</p><p>当然这个机制无法解决小内存无法使用的问题</p><h3 id="移动数据"><a href="#移动数据" class="headerlink" title="移动数据"></a>移动数据</h3><p>在标记清除算法中的标记阶段，会移动非垃圾数据，使它们尽可能紧凑地放在内存中。<br><img src="https://i.loli.net/2021/06/18/kUBnZb9fpEO1veG.png" alt="move.png"></p><p>缺点在于移动数据会带来不小的开销</p><h3 id="复制式回收"><a href="#复制式回收" class="headerlink" title="复制式回收"></a>复制式回收</h3><p>将内存划分为两个相等的空间 <code>From</code>, <code>To</code>。 程序执行使用 <code>From</code>空间，在垃圾回收扫描时，将能追踪的数据复制到 <code>To</code> 空间。所有空间复制完成后，将<code>From</code> 和 <code>To</code> 空间交换，并清除原<code>From</code>空间的数据。</p><p>这种方法会占用一般的内存空间，为了提高内存使用率，只会在一部分的内存空间使用，并搭配其他的回收机制。</p><h3 id="分代回收"><a href="#分代回收" class="headerlink" title="分代回收"></a>分代回收</h3><h3 id="弱分代假说"><a href="#弱分代假说" class="headerlink" title="弱分代假说"></a>弱分代假说</h3><p>大部分对象都在年轻时死亡。</p><p>我们将只存活1， 2次回收的对象称为新生代对象。而经历过多次垃圾回收的对象为老年代对象。实践证明，新生代对象成为垃圾的概率要高于老年代对象。</p><p>我们可以将数据分成新生代和老年代，降低老年代数据的垃圾回收扫描频率，这将提升垃圾回收效率。</p><h2 id="引用计数式垃圾回收"><a href="#引用计数式垃圾回收" class="headerlink" title="引用计数式垃圾回收"></a>引用计数式垃圾回收</h2><p>以上均为追踪式垃圾回收，引用计数式垃圾回收有所不同。</p><p>该垃圾回收在执行过程中，会更新对象的引用计数，当引用计数更新为0时，说明该数据不再有用，可以进行垃圾回收。这种回收机制可以将之前的追踪代价分摊到每次对数据的操作中。</p><p>但是，引用计数的均摊思路，如果在高频率开辟内存的场景下，仍然带来不小的开销。</p><h1 id="STW"><a href="#STW" class="headerlink" title="STW"></a>STW</h1><p>每种垃圾回收策略都无法完美解决各式各样的缺陷。同样的，以上的垃圾回收策略均无可避免的需要 <code>Stop the World</code>， 这将会暂停用户程序，为了避免长时间 STW 带给用户影响，我们可以将 STW 分成多次执行，将一次垃圾回收拆分成多次，和用户程序交替执行。这叫做 <code>增量式回收</code>。</p><p>这可能带来的问题是，在某段垃圾回收标记了一个黑色对象，用户程序立马修改它，导致垃圾回收机制的误判，这里就得使用 <code>读写屏障</code> 机制，详见上一篇文章。</p><h2 id="读屏障"><a href="#读屏障" class="headerlink" title="读屏障"></a>读屏障</h2><p>补充一个读屏障。</p><p>在 <code>FROM</code> <code>TO</code> 复制回收机制中。</p><p><img src="https://i.loli.net/2021/06/18/LP5Fzi1HGnc96AB.png" alt="fromti.png"></p><p>当A已经复制到 <code>to</code> 空间上后，用户程序读取了 <code>From</code> 空间的旧数据，B复制到了 A,由于B建立的指针指向了旧的A，当<code>FROM</code>空间被销毁，B指向的旧A也不复存在，此时再去访问旧A，就会出错。</p><p>此时需要引入一个读屏障：</p><ul><li>当我们读取的数据有新副本时，直接读取 <code>To</code> 空间的新副本。</li></ul><h1 id="多核"><a href="#多核" class="headerlink" title="多核"></a>多核</h1><p>多线程并行执行垃圾回收的场景，被称为 <code>并行垃圾回收</code>。</p><p>并发GC的问题在于，很容易导致有的协程的GC忙碌，而有的线程空闲。如果使用负载均衡，这也会带来同步的开销。</p><p>同时，并行GC还有的问题是，<code>FROM-TO</code>复制回收还需要避免数据对象被重复复制。</p><ul><li><p>用户程序和GC并行执行的垃圾回收被称为 <code>并发垃圾回收</code>。</p></li><li><p>在GC的某个阶段进行STW，被称为 <code>主体并发式垃圾回收</code></p></li><li><p>再增加增量垃圾回收机制，又会出现 <code>主题并发增量式垃圾回收</code></p></li></ul><p><img src="https://i.loli.net/2021/06/18/GNYLQxF534jwTaU.png" alt="gc-type.png"></p><h1 id="Golang采用了哪些？"><a href="#Golang采用了哪些？" class="headerlink" title="Golang采用了哪些？"></a>Golang采用了哪些？</h1><p>Golang 采用了 三色标记法 的 <code>标记-清除</code> 算法 + 主体并发增量式回收 + 插入，删除的混合写屏障</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gc </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>golang之defer和panic</title>
      <link href="2021/06/16/golang%E4%B9%8Bdefer%E5%92%8Cpanic/"/>
      <url>2021/06/16/golang%E4%B9%8Bdefer%E5%92%8Cpanic/</url>
      
        <content type="html"><![CDATA[<h1 id="panic-和-defer-的一般执行流程"><a href="#panic-和-defer-的一般执行流程" class="headerlink" title="panic 和 defer 的一般执行流程"></a>panic 和 defer 的一般执行流程</h1><p>Golang的每一个goroutine上都会有 <code>*_defer</code>, <code>*_panic</code> 的头指针，每次发生新的panic， 都会在链表头上加入panic。defer与之类似。</p><p><img src="https://i.loli.net/2021/06/16/Y84sWgIQvpVmxwG.png" alt="case1.png"></p><p>在这个场景下，当程序执行到panic时，goroutine的defer链表已经储存了两个defer函数。此时，程序会先将panic储存到panic链表中，再从defer链表中取出defer函数执行。</p><p><img src="https://i.loli.net/2021/06/16/QYjncWOBK65s4gx.png" alt="link.png"></p><p>由panic触发的defer，在执行中有所不同。先看下defer的结构：</p><p><img src="https://i.loli.net/2021/06/16/NT9a4d5yDlSpOqh.png" alt="_defer.png"></p><ul><li>先将 <code>started</code> 置 <code>true</code></li><li>将 <code>_panic</code> 指向当前panic</li></ul><p>这种设计，是为了应对defer函数的执行失败。比如：</p><p><img src="https://i.loli.net/2021/06/16/5CMwiJmxZHaELfS.png" alt="case2.png"></p><p>我们让A1也发生panic。当程序执行到 <code>A1</code> 的 <code>panic</code> 时, <code>goroutine</code> 的 <code>_panic</code>链表又会增加一个 <code>panic</code> 。</p><p>此时，新的 <code>panic</code> 也会触发执行 <code>_defer</code> 链表中的函数，并发现第一个defer函数上标记的 <code>panic</code> 不是自己，此时，程序会将 <code>_panic</code> 链表中对应的 <code>panic</code> 中止。</p><p><img src="https://i.loli.net/2021/06/16/gHTuS8jRka1L4eh.png" alt="panic-shutdown.png"></p><p>此时，需要展示一下 <code>panic</code> 的结构体。</p><p><img src="https://i.loli.net/2021/06/16/EedOavxV5HyzwNk.png" alt="panic-struct.png"></p><p>最后， 在没有 <code>recover</code> 的情况下，<code>panic</code> 打印会从链表尾部，打印至头部。</p><h2 id="小结1"><a href="#小结1" class="headerlink" title="小结1"></a>小结1</h2><p>无 recover 的 panic 执行流程的要点在于：</p><ul><li><code>panic</code> 执行 <code>defer</code> 函数会先标记defer函数，目的是嵌套的 <code>panic</code> 可以中止之前的 <code>panic</code></li><li>所有的panic 都会输出，且顺序输出。</li></ul><h1 id="recover"><a href="#recover" class="headerlink" title="recover"></a>recover</h1><p><code>recover</code> 只会把 <code>panic</code> 结构体上的 <code>recovered</code> 字段置 <code>true</code>。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tpc 粘包</title>
      <link href="2021/06/16/tpc-%E7%B2%98%E5%8C%85/"/>
      <url>2021/06/16/tpc-%E7%B2%98%E5%8C%85/</url>
      
        <content type="html"><![CDATA[<h1 id="0-背景"><a href="#0-背景" class="headerlink" title="0. 背景"></a>0. 背景</h1><p>socket网络编程采用端对端通信，可以使用 [<code>源IP</code>, <code>源端口</code>， <code>目的IP</code>, <code>目的端口</code>, <code>传输层协议</code>] 这样的五元组来描述一个连接。发送者往往发送多个包给接收者，为了更高效地发送数据包，采用了优化算法（<code>Nagle</code> 算法）， 将<code>多次</code>，<code>间隔小</code>,<code>数据量小</code>的数据，合并成一个数据量大的数据块，然后进行封装包。同时, 接收者也需要使用高效的拆包机制来分辨这些数据</p><h1 id="1-什么是TCP粘包"><a href="#1-什么是TCP粘包" class="headerlink" title="1.什么是TCP粘包"></a>1.什么是TCP粘包</h1><h2 id="发送者"><a href="#发送者" class="headerlink" title="发送者"></a>发送者</h2><p>TCP默认使用 <code>Nagle</code>算法，用于减少网络中报文数量，其主要：</p><ul><li><ol><li>只有当上一个分组得到确认后，才会发送下一个分组</li></ol></li><li><ol start="2"><li>手机多个小分组，当确认到达后，一起发送</li></ol></li></ul><h2 id="接收者"><a href="#接收者" class="headerlink" title="接收者"></a>接收者</h2><p>TPC接收到数据包后，不会马上交给应用层处理，而是将其缓存，而应用程序需要主动从缓存中接收分组。</p><p>在这种情况下，当满足以下条件，就会发生TCP <code>粘包</code>:</p><ul><li>TPC接收数据包到缓存的速度大于应用程序从缓存读取数据包的数据。</li><li>当多个包被缓存，应用程序有可能读取到多个首尾相接的包。</li></ul><h2 id="可能产生的问题"><a href="#可能产生的问题" class="headerlink" title="可能产生的问题"></a>可能产生的问题</h2><p>比如写的一段程序，向服务端发送两次数据，我希望服务端分别对这两个数据进行处理，但是服务器在一次接收时，将两条数据都读出来了。如果没有很好地处理这个场景，数据很容易被错误处理，甚至被认为时错误而被丢掉，导致服务端不能高效处理服务。</p><h1 id="2-TCP粘包的谬误"><a href="#2-TCP粘包的谬误" class="headerlink" title="2.TCP粘包的谬误"></a>2.TCP粘包的谬误</h1><p>实际上<code>TCP粘包</code>这个名词本身就不合理，因为：</p><ul><li>TCP本身就没有包的概念， 它是一个面向流的协议</li><li>而所谓的粘包是指，开发者在应用层封装的数据，开发者希望TCP能将这些数据自动拆分，然而TCP为了节省流量，会将包合并后发送。这并不是TCP的问题。</li></ul><h1 id="3-解决思路"><a href="#3-解决思路" class="headerlink" title="3. 解决思路"></a>3. 解决思路</h1><ol><li>格式化数据：给每条数据都设置固定的格式，（开始符， 结束符）。特点简单，但是要保证开始符结束符不会出现在数据内部。</li><li>设置发送长度：发送数据时，将长度一并发送，这样应用层可以根据长度分辨数据的开始与结束</li></ol><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><p>TCP 粘包本身就不是问题，但是通过这个“问题”可以学到一些非常基本的网络编程的规范。（应用开发者应该解决好自己定义的数据包分包的问题，而不是交给TCP解决）</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> tcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入探讨Golang的类型系统</title>
      <link href="2021/06/09/%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8Golang%E7%9A%84%E7%B1%BB%E5%9E%8B%E7%B3%BB%E7%BB%9F/"/>
      <url>2021/06/09/%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8Golang%E7%9A%84%E7%B1%BB%E5%9E%8B%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="先讲一讲Golang的方法"><a href="#先讲一讲Golang的方法" class="headerlink" title="先讲一讲Golang的方法"></a>先讲一讲Golang的方法</h1><pre><code>type T struct &#123;    name string&#125;func (t T) F1() &#123;    fmt.Println(t.name)&#125;func main()&#123;    t := T&#123;name: &quot;a&quot;&#125;    t.F1()&#125;</code></pre><p>像上面这段代码，我们定义了一个结构体，并给这个结构体关联了一个方法， 并使用 <code>t.F1()</code>语句调用了这个方法。</p><p>方法的本质是一个函数，只是这个函数在被调用时，接收者会作为第一个参数传入。（<code>t.F1()</code> 的本质是 <code>T.F1(t)</code>。 前者的写法只是语法糖）</p><p>在编译阶段，我们可以获取变量，类型，方法等参数。</p><p>到了执行阶段，像 <code>反射</code>， <code>接口</code>， <code>类型断言</code> 这类语言特性/ 机制，我们也需要动态获取数据类型信息。</p><h1 id="我们先看看Golang有哪些类型？"><a href="#我们先看看Golang有哪些类型？" class="headerlink" title="我们先看看Golang有哪些类型？"></a>我们先看看Golang有哪些类型？</h1><h2 id="内置类型-build-in"><a href="#内置类型-build-in" class="headerlink" title="内置类型(build-in)"></a>内置类型(build-in)</h2><pre><code>int8int16int32int64intbytestringslicefuncmap</code></pre><h2 id="自定义类型"><a href="#自定义类型" class="headerlink" title="自定义类型"></a>自定义类型</h2><pre><code>type typ inttype T struct &#123;    name string&#125;type I interface&#123;    Name() string&#125;</code></pre><p>在 Golang 官方定义中， 内置类型不能定义方法，接口类型是方法的无效接收者。</p><p>换句话说，我们只能给 <code>type T int</code> 和 <code>type T struct&#123;&#125;</code> 定义方法。</p><h2 id="类型元数据"><a href="#类型元数据" class="headerlink" title="类型元数据"></a>类型元数据</h2><p>无论是内置类型还是自定义类型，每种类型都有全局唯一的 <code>类型元数据</code>。</p><p>类型元数据记录了如下信息:(rutime/type.go)</p><pre><code>type _type struct &#123;    size        uintptr    hash        uint32    tflag       tflag    align       uint8    fieldAlign  uint8    kind        uint8    ....&#125;</code></pre><p>有些类型元数据可能还需要对信息进行扩展，比如切片类型</p><pre><code>type slicetype struct &#123;    typ     _type    elem    *_type&#125;</code></pre><p>因为切片类型可以是整型切片，也可以是字符串切片，因此，它还需要一个elem字段来描述储存元素的类型。比如整形切片，它的类型元数据的elem字段需要指向整形的类型元数据。</p><p>对于自定义类型，它们可能还需要更多的描述，这些描述被储存在 <code>uncommontype</code> 结构体中。</p><pre><code>type uncommontype struct &#123;    pkgpath nameOff    mcount  uint16 // 方法数    xcount  uint16 // exported方法数    moff    uint32 // 相对于方法元数据数据的偏移值    _       uint32 // unused&#125;</code></pre><h2 id="类型的两种写法区别"><a href="#类型的两种写法区别" class="headerlink" title="类型的两种写法区别"></a>类型的两种写法区别</h2><ul><li><code>type MyType1 = int32</code><ul><li><code>Mytype1</code> 和 <code>int32</code> 会被关联到同一个类型元数据，比如 <code>rune</code> 和 <code>int32</code> 就是这样的关系。</li></ul></li><li><code>type MyType2 int32</code><ul><li><code>MyType2</code> 和 <code>int32</code> 会各自拥有自己的类型元数据。</li></ul></li></ul><h1 id="接口类型"><a href="#接口类型" class="headerlink" title="接口类型"></a>接口类型</h1><h2 id="空接口类型"><a href="#空接口类型" class="headerlink" title="空接口类型"></a>空接口类型</h2><p>空接口类型可以接收任意类型的数据，也就是说它需要记录接收数据的类型和数据的地址。</p><pre><code>type eface struct &#123;    _type *_type            // 动态类型    data  unsafe.Pointer    // 动态值&#125;</code></pre><p>下图展示了一个空接口变量赋值后，其元数据的变化。</p><p><img src="https://i.loli.net/2021/06/09/93lIxa4JU6GHAZj.png" alt="interface.png"></p><h2 id="非空接口类型"><a href="#非空接口类型" class="headerlink" title="非空接口类型"></a>非空接口类型</h2><p>非空接口类型即拥有一个方法列表的类型。一个变量要想赋值给一个非空接口类型，它需要实现这个接口所有的方法。</p><pre><code>type iface struct &#123;    tab  *itab    data unsafe.Pointer // 指向接口的动态值&#125;</code></pre><p><img src="https://i.loli.net/2021/06/09/NtDmKZUFSEWP2i3.png" alt="non-nil-interface.png"></p><p>非空接口的 </p><ul><li><code>tab.inter</code> 指向了接口类型的元数据，其中的 <code>mhdr</code> 是接口的方法列表。</li><li><code>_type</code> 是接口的动态类型</li><li><code>hash</code> 是类型哈希值，用于接口类型的快速比较</li><li><code>fun</code> 是方法地址数组</li></ul><p>itab 结构体中的值，在它被确定后就不会发生改变，所以它是可复用的。</p><p><img src="https://i.loli.net/2021/06/09/7HebRa1sKAwzqyk.png" alt="itab.png"></p><p>Golang 会将接口类型和动态类型作为一个组合key， itab结构体指针为value, 形成一张轻量级的哈希表。当我们需要一个itab时，会先在哈希表中查找，如果找到了，直接复用，否则会创建一个新的itab，添加到这张哈希表中。</p><h1 id="类型断言"><a href="#类型断言" class="headerlink" title="类型断言"></a>类型断言</h1><p>像上面提到的 <code>空接口</code> 和 <code>非空接口</code> ，被叫做 <code>抽象类型</code>; 与之对应的 int, string, slice 等类型就是具体类型。</p><p>类型断言是作用在抽象类型之上的， 而断言的目标类型，可以是具体类型，也可以是非空接口。两两组合，可以得到4种断言。</p><ul><li>空接口.(具体类型)</li><li>非空接口.(具体类型)</li></ul><h2 id="空接口-具体类型"><a href="#空接口-具体类型" class="headerlink" title="空接口.(具体类型)"></a>空接口.(具体类型)</h2><p><code>r, ok := interface.(*type)</code></p><p>对于这种类型断言，我们只需要检查 interface 元数据中的 <code>_type</code> 字段是否指向 断言的<code>*type</code>， 是则 Ok 为 true, 否则 ok 为 false，且 r 为 nil</p><h2 id="非空接口-具体类型"><a href="#非空接口-具体类型" class="headerlink" title="非空接口.(具体类型)"></a>非空接口.(具体类型)</h2><p>与空接口不同的是，这种断言方法只需检查 itab 是否指向目标类型结构体。</p><h2 id="空接口-非空接口"><a href="#空接口-非空接口" class="headerlink" title="空接口.(非空接口)"></a>空接口.(非空接口)</h2><p>在我们检查接口类型元数据时， 我们需要比对 空接口的方法元数据数组和目标类型的方法列表是否相同。当然我们不通过空接口的类型元数据直接比对，还是通过itab缓存。但是通过itab缓存时，虽然查到了目标itab，但还是需要比对itab中的方法 <code>f[0]</code> 是否为 0。 这是因为，在某次类型断言失败时，itab缓存还是会添加itab到哈希表中，只是会将其方法列表置0，代表断言失败。</p><h2 id="非空接口-非空接口"><a href="#非空接口-非空接口" class="headerlink" title="非空接口.(非空接口)"></a>非空接口.(非空接口)</h2><p>同样，从itab缓存查itab结构体指针，并去查f[0]是否为0.</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Golang 的类型断言的关键在于明确接口动态类型，与对应类型实现了哪些方法。</p><p>这些明确内容的关键点在于 <code>类型元数据</code> <code>空接口</code> <code>非空接口</code></p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 类型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vsCode 添加至右键</title>
      <link href="2021/06/08/vsCode-%E6%B7%BB%E5%8A%A0%E8%87%B3%E5%8F%B3%E9%94%AE/"/>
      <url>2021/06/08/vsCode-%E6%B7%BB%E5%8A%A0%E8%87%B3%E5%8F%B3%E9%94%AE/</url>
      
        <content type="html"><![CDATA[<ul><li>将下列配置粘到一个新建的 <code>xxx.reg</code> 文件中</li></ul><pre><code>Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\*\shell\VSCode]@=&quot;Open with Code&quot;&quot;Icon&quot;=&quot;C:\\Program Files\\Microsoft VS Code\\Code.exe&quot;[HKEY_CLASSES_ROOT\*\shell\VSCode\command]@=&quot;\&quot;C:\\Program Files\\Microsoft VS Code\\Code.exe\&quot; \&quot;%1\&quot;&quot;Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\Directory\shell\VSCode]@=&quot;Open with Code&quot;&quot;Icon&quot;=&quot;C:\\Program Files\\Microsoft VS Code\\Code.exe&quot;[HKEY_CLASSES_ROOT\Directory\shell\VSCode\command]@=&quot;\&quot;C:\\Program Files\\Microsoft VS Code\\Code.exe\&quot; \&quot;%V\&quot;&quot;Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\Directory\Background\shell\VSCode]@=&quot;Open with Code&quot;&quot;Icon&quot;=&quot;C:\\Program Files\\Microsoft VS Code\\Code.exe&quot;[HKEY_CLASSES_ROOT\Directory\Background\shell\VSCode\command]@=&quot;\&quot;C:\\Program Files\\Microsoft VS Code\\Code.exe\&quot; \&quot;%V\&quot;&quot;</code></pre><p>注意路径和实际是否一致。</p><p>实际就是添加注册表</p>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vsCode </tag>
            
            <tag> windows </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mutex 互斥锁</title>
      <link href="2021/06/07/mutex-%E4%BA%92%E6%96%A5%E9%94%81/"/>
      <url>2021/06/07/mutex-%E4%BA%92%E6%96%A5%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h1 id="mutex"><a href="#mutex" class="headerlink" title="mutex"></a>mutex</h1><pre><code>type Mutex struct &#123;    state int32    sema uint32&#125;</code></pre><ul><li>state:<ul><li>代表锁的状态</li><li>mutex的加锁与解锁都是通过 <code>atomic</code> 包提供的函数原子性地操作该字段实现的</li></ul></li><li>sema:<ul><li>一个信号量</li><li>用作等待队列</li></ul></li></ul><h2 id="mutex-的-正常模式"><a href="#mutex-的-正常模式" class="headerlink" title="mutex 的 正常模式"></a>mutex 的 正常模式</h2><p>一个goroutine 会先自旋几次，尝试获得锁，如果仍然没有获得锁，则通过信号量 <code>sema</code> 排队等待（进入等待队列）。</p><p>但是当锁被释放时，队首的goroutine也不会立即获得锁，而是与其他后来的自旋的goroutine竞争。一般情况下，处于自旋状态的goroutine会更先抢到锁，因为它们一直处于运行状态，而队列里出来的goroutine由于刚唤醒，还会因为需要分配cpu资源而需要消耗一点时间。这种情况下，为了保证先进先出，即使竞争失败了，仍然插入队列头部而不是尾部。</p><h2 id="mutex的饥饿模式"><a href="#mutex的饥饿模式" class="headerlink" title="mutex的饥饿模式"></a>mutex的饥饿模式</h2><p>当一个goroutine本次加锁等待时间超过1ms后，它会将mutex从 <code>正常模式</code>切换成 <code>饥饿模式</code> 。</p><p>在饥饿模式下，锁一旦被释放，就会直接传递给等待队列的头部goroutine。而如果有一些后来的goroutine需要这个锁，它们不会像正常模式一样自旋，而是直接被加入到队列尾部。</p><p><code>饥饿模式</code> 也可以再切换回正常模式：</p><ul><li>当一个goroutine获得锁，且等待时间 <code>&lt; 1ms</code>时。</li><li>当等待队列为空时 (即等待队列最后一个goroutine获得锁。)</li></ul><h2 id="两者对比"><a href="#两者对比" class="headerlink" title="两者对比"></a>两者对比</h2><ul><li><p>正常模式</p><ul><li>这是一个自旋和排队共存的模式</li><li>[优点] 由于自旋可以在无需唤醒的状态下直接获得锁，因此，正常模式可以保证Mutex有更好的。</li><li>[缺点] 但是, 这个模式可能导致队列尾端的goroutine一直抢不到锁（尾端延迟）</li></ul></li><li><p>饥饿模式</p><ul><li>这个模式会强制所有goroutine排队</li><li>它在牺牲一定性能的情况下， 解决正常模式的尾端延迟问题</li></ul></li></ul><p>两种模式之间的切换，既保证锁的效率，又能顾及公平性，不会导致某个goroutine过长时间的等待。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 锁 </tag>
            
            <tag> mutex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊聊Golang之context</title>
      <link href="2021/06/05/%E8%81%8A%E8%81%8AGolang%E4%B9%8Bcontext/"/>
      <url>2021/06/05/%E8%81%8A%E8%81%8AGolang%E4%B9%8Bcontext/</url>
      
        <content type="html"><![CDATA[<h1 id="context-解决的问题"><a href="#context-解决的问题" class="headerlink" title="context 解决的问题"></a>context 解决的问题</h1><p>在实际开发中，经常会出现一个goroutine创建多个goroutine的场景。<br><img src="https://i.loli.net/2021/06/05/nrJzT1Si4PAHBxR.png" alt="goroutine.png"></p><p>context 用于解决多goroutine之前的通信问题，比如 G 可以控制它的子线程超时退出，取消，传递信息等。</p><p>当然，控制goroutine的方法有很多，最常见的就是通过 select + channel 实现超时与取消。</p><pre><code>    done := make(chan struct&#123;&#125;, 1)    go func() &#123;        // 发送请求等任务        done &lt;- struct&#123;&#125;&#123;&#125;    &#125;(ctx)    select &#123;    case &lt;-done:        fmt.Println(&quot;call successfully!!!&quot;)        return    case &lt;-time.After(time.Duration(800 * time.Millisecond)):        fmt.Println(&quot;timeout!!!&quot;)        return    &#125;</code></pre><p>之所以还需要context,就是因为 简单的 select + channel 无法解决更复杂的场景：<br>正如图中协程G开启的协程g2，它也会开启g4, g5。 协程G希望给g2设置超时，取消机制，但如果g2没有及时将g4, g5 关闭，协程G将无法和g4, g5 建立联系，也就是说g4, g5会一直开启并占用系统资源。当然，只需要在g2中写好关闭它的子协程的业务逻辑，可以避免这个问题，但是如果协程更多，更复杂，那么需要额外添加的代码就更多，也更容易出错。</p><h1 id="Context-一个接口，四个实现，六个函数"><a href="#Context-一个接口，四个实现，六个函数" class="headerlink" title="Context 一个接口，四个实现，六个函数"></a>Context 一个接口，四个实现，六个函数</h1><p>一个接口</p><ul><li>Context</li></ul><p>四个实现</p><ul><li>emptyCtx</li><li>cancelCtx</li><li>timerCtx</li><li>valueCtx</li></ul><p>六个函数</p><ul><li>Background</li><li>TODO</li><li>WithCancel</li><li>WithDeadline</li><li>WithTimeout</li><li>WithValue</li></ul><h2 id="context-接口"><a href="#context-接口" class="headerlink" title="context 接口"></a>context 接口</h2><pre><code>type Context interface &#123;    Deadline() (deadline time.Time, ok bool)    Done() &lt;-chan struct&#123;&#125;    Err() error    Value(key interface&#123;&#125;) interface&#123;&#125;&#125;</code></pre><h2 id="emptyCtx"><a href="#emptyCtx" class="headerlink" title="emptyCtx"></a>emptyCtx</h2><p><code>emptyCtx</code> 是一个整型变量， 它实现了 <code>context</code> 接口，但是什么也没做。<code>Background</code> 和 <code>TODO</code> 两个函数都会创建 <code>emptyCtx</code>。</p><p><code>Background()</code> 用于初始化一个 ctx。它的接口类型是 <code>Context</code>, 动态类型是 <code>emptyCtx</code>， 值的本质是一个0。</p><p><code>TODO()</code> 虽然底层实现和 <code>Background()</code> 一模一样，但官方希望它被用在，当我们不知道使用哪个context或者函数当前并不需要引入一个 context。换句话说，它被用在代码还没写完的部分，类似我们经常在注释里写的 TODO。</p><h2 id="cancelCtx"><a href="#cancelCtx" class="headerlink" title="cancelCtx"></a>cancelCtx</h2><p>这是可取消的context。</p><pre><code>type cancelCtx struct &#123;    Context    mu       sync.Mutex                done     chan struct&#123;&#125;    children map[canceler]struct&#123;&#125;    err      error&#125;</code></pre><ul><li>mu: 保证线程安全</li><li>done：context取消通知</li><li>children：记录以当前context为根节点的所有可取消的子context，便于级联取消</li><li>err：存储取消时的错误信息</li></ul><p><code>WithCancel</code> 能将一个context包装成可取消的。</p><pre><code>ctx := context.Background()ctx1, cancel := context.WithCancel(ctx)</code></pre><h2 id="timerCtx"><a href="#timerCtx" class="headerlink" title="timerCtx"></a>timerCtx</h2><pre><code>timer *time.Timer // Under cancelCtx.mu.deadline time.Time</code></pre><p><code>timerCtx</code> 也是一个可取消的 context。 它在 <code>cancelCtx</code> 的基础上又封装了一个计时器和一个截止时间。</p><p>它可以用 <code>WithDeadline</code> 和 <code>WithTimeout</code> 创建。</p><ul><li>WithDeadline: 指定一个时间点</li><li>WithTimeout: 指定时间段</li></ul><h2 id="valueCtx"><a href="#valueCtx" class="headerlink" title="valueCtx"></a>valueCtx</h2><p>valueCtx 能打包键值对</p><pre><code>ctx := context.Background()key1 := &quot;key1&quot;ctx1 := context.WithValue(ctx, key1, &quot;value1&quot;)</code></pre><p>使用valueCtx打包键值对时会出现这样的问题：<br>当对同一个key赋值的两个context, 它们最终的键值对是相同的。</p><pre><code>ctx := context.Background()key1 := &quot;key1&quot;key2 := &quot;key2&quot;ctx1 := context.WithValue(ctx, key1, &quot;value1&quot;)ctx2 := context.WithValue(ctx1, key2, &quot;value2&quot;)fmt.Println(&quot;key1 -&gt;&quot;, ctx2.Value(key1))fmt.Println(&quot;key1 -&gt;&quot;, ctx2.Value(key2))----key1 -&gt; value2key2 -&gt; value2</code></pre><p>这是因为 <code>Value()</code> 在查找前回去比对要 <code>查找的key</code> 和 <code>当前context中的key</code>。如果相同，直接返回当前context的key。</p><p>为了规避这个情况，我们可以将key的类型换成自定义类型，使 <code>Value()</code>中的 <code>c.key == key</code> 失效。</p><pre><code>type keyType1 stringvar key1 keyType1 = &quot;key1&quot;</code></pre><p>另外，context 储存的键值对不支持修改。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> context </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis分布式锁</title>
      <link href="2021/06/04/%E8%81%8A%E8%81%8A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>2021/06/04/%E8%81%8A%E8%81%8A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h1 id="涉及指令"><a href="#涉及指令" class="headerlink" title="涉及指令"></a>涉及指令</h1><ul><li><code>SETNX key value</code>: （nx: not exist） key不存在时，设置成value,返回1; 没设置成功，返回0</li><li><code>EXPIRE key locktime</code>: 设置key有效时常</li><li><code>DEL key</code>:删除</li><li><code>GETSET key value</code>: 先GET,再SET,先返回value,没有就返回nil。再实现设置操作。</li></ul><h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p>分布式锁就是 对于一个所有进程都能访问到的资源上，设置一个锁资源，让这些进程来竞争这个锁。</p><p>我们希望分布式锁：</p><ul><li>响应快</li><li>性能高</li><li>与业务无关</li></ul>]]></content>
      
      
      <categories>
          
          <category> redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> redis </tag>
            
            <tag> 锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>探讨一下golang map</title>
      <link href="2021/06/04/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8Bgolang-map/"/>
      <url>2021/06/04/%E6%8E%A2%E8%AE%A8%E4%B8%80%E4%B8%8Bgolang-map/</url>
      
        <content type="html"><![CDATA[<h1 id="为什么Golang-map-是无序的？"><a href="#为什么Golang-map-是无序的？" class="headerlink" title="为什么Golang map 是无序的？"></a>为什么Golang map 是无序的？</h1><h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>Golang中每次遍历Map元素，输出的数据顺序不一致。</p><p>比如</p><pre><code>hash := make(map[int]int)for i := 0; i &lt; 10; i++ &#123;    hash[i] = i&#125;for key := range hash &#123;    fmt.Printf(&quot;%d &quot;, key)&#125;</code></pre><p>我按顺序写入map，但当用 <code>for ... range</code> 遍历，打印出来的却是乱序。</p><pre><code>8 9 0 2 4 6 7 1 3 5</code></pre><h2 id="map遍历源码"><a href="#map遍历源码" class="headerlink" title="map遍历源码"></a>map遍历源码</h2><p>在 <code>runtime/map.go</code> 中，涉及map遍历有这么一段代码：</p><pre><code>r := uintptr(fastrand())if h.B &gt; 31-bucketCntBits &#123;    r += uintptr(fastrand()) &lt;&lt; 31&#125;</code></pre><p>每次遍历都会随机指定一个起始点。</p><p>当然，这不会是真正原因。因为如果只是遍历起始点随机，map的遍历应该是局部有序的，然而事实并非如此。</p><h2 id="无序的本质"><a href="#无序的本质" class="headerlink" title="无序的本质"></a>无序的本质</h2><h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><p>golang map的底层实现是用了 哈希表 这类的数据结构。哈希表的特点就是在冲突尽可能少的情况下实现高效性。换句话说，golang需要通过设计来减少冲突的发生。他们使用的其中之一的策略就是随机性。</p><p>下面来讲讲golang设计的哈希表吧。</p><h2 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h2><p>golang 设计的哈希表，在选择桶的时候，使用了与运算的方法。 =&gt; hash &amp; (m - 1)</p><ul><li><ol><li>先对 <code>key</code> 进行 <code>hash</code>，取哈希值的低八位，确定bucket 编号 N</li></ol></li><li><ol start="2"><li>遍历 N bucket 中的每个位置，当有个没有写入的位置，写入哈希值的高八位</li></ol></li><li><ol start="3"><li>如果 N bucket 中出现相同的topHash, 比较存入的key和要写入的key是否相同，相同则覆盖值；不同说明发生了冲突，继续往下找空余的空间。（开放地址法）</li></ol></li></ul><p>golang 写入的随机性在于，在给map开辟空间之前，会生成一个随机种子存放在 <code>hmap.hash0</code> 中。这种做法就是希望能尽量减少哈希冲突。</p><h2 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h2><p>golang在每一个bucket后面都有一块 能存放8个key的 bmap。 bmap 的大小不能设计过大，因为这也会降低哈希表的性能。所以，当我们原先给 map 开辟的 buckets 不够用时，需要扩容。</p><p>当哈希表满了， 会开辟出足够多的新桶。但是，哈希表不会将旧桶数据一次性迁移到新桶上。在 <code>hmap</code> 结构体中 <code>oldbuckets</code> 指向旧桶， <code>nevacuate</code> 标记旧桶迁移进度。哈希表每一次的读写操作，都会进行一次旧数据的迁移。像这种将迁移分摊给每次哈希表的操作中的扩容方式叫做 <code>渐进式扩容</code>。 如果一次性进行数据迁移，哈希表性能必然会出现 <code>抖动</code> ， 这种 <code>渐进式扩容</code> 就能很好地保证了哈希表的性能稳定性。</p><h2 id="溢出桶"><a href="#溢出桶" class="headerlink" title="溢出桶"></a>溢出桶</h2><p>先来看一下本哈希表中一个桶的构造是什么样的吧</p><p><img src="https://i.loli.net/2021/06/04/gx38I1OpQboA2Gl.png" alt="bucket.png"></p><p>在一个bucket中，为了数据更加紧凑，会首先存储 k-v 键值对哈希值的高八位，一共只能存八个，也就是说一个bucket只能存8对键值对。当一个bucket存满了，还可以再往后添加一个bucket，这叫溢出桶，溢出桶的结构和bucket一模一样。</p><p>溢出桶的出现是为了一定程度减少扩容的次数，在上面我们介绍了本哈希表的渐进式扩容，虽然将扩容迁移的负担平摊到了每一步的哈希表操作，但如果扩容次数增加，同样会影响哈希表的性能。所以，溢出桶出现，是希望，如果只是少量的数据溢出，只需要再开开辟一个桶来存放，而无需进行扩容操作。</p><p>实际中，哈希表如果分配了超过 2 ^ 4 个桶，会被认为需要溢出桶的概率比较大，会预分配 2 ^ (B-4)个溢出桶。</p><p>溢出桶的相关信息被存放在 <code>mapextra</code>。</p><h2 id="扩容规则"><a href="#扩容规则" class="headerlink" title="扩容规则"></a>扩容规则</h2><h3 id="翻倍扩容"><a href="#翻倍扩容" class="headerlink" title="翻倍扩容"></a>翻倍扩容</h3><p>golang默认的负载因子是 <code>6.5</code>。 如果 <code>count / (2^B)</code> 超过这个值，会触发翻倍扩容。翻倍扩容即分配的新桶数目是旧桶数目的两倍。</p><p>哈希表扩容后，旧桶数据需要迁移到新桶中。为了减少新桶哈希冲突，旧桶数据需要均匀分配给新桶中的每一个桶。其策略是，将旧桶中每一个哈希值都再一次进行与运算。 假设我们的旧桶宽度为 4， 新分配的新桶是8。 我们进行 <code> hash &amp; 111</code> 的与操作。0号桶中的数据会被均匀分配给新桶的0 和4号桶，其他桶一次类推。</p><h3 id="等量扩容"><a href="#等量扩容" class="headerlink" title="等量扩容"></a>等量扩容</h3><p>当哈希表的负载因子没超过上限，但溢出桶比较多， 此时为了减少溢出桶的数量，会采取等量扩容。等量扩容即新开辟的桶的数量和旧桶一致。</p><p>这种机制主要是应对哈希表大量删除操作的场景。</p><p>我们可以想象这样的场景：</p><ul><li>哈希表添加了大量数据，产生一些溢出桶。</li><li>之后进行了删除操作，溢出桶大部分的数据都被删除。</li><li>产生了很多较空的溢出桶。</li></ul><p>溢出桶同样会影响性能，因此，等量扩容是减少溢出桶的数量，也是为了维持性能的稳定。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 哈希 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>虚拟内存地址空间</title>
      <link href="2021/06/03/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/"/>
      <url>2021/06/03/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4/</url>
      
        <content type="html"><![CDATA[<h1 id="虚拟内存地址空间的分布"><a href="#虚拟内存地址空间的分布" class="headerlink" title="虚拟内存地址空间的分布"></a>虚拟内存地址空间的分布</h1><p><img src="https://i.loli.net/2021/06/03/geWDOKmTUXCZI31.png" alt="Virtual-memory-address-space.png"></p><p>我们可以对内存空间进行如下分区管理：</p><h2 id="代码段"><a href="#代码段" class="headerlink" title="代码段"></a>代码段</h2><p> 一段程序经过编译器编译成机器指令存储在可执行文件里，程序运行时，程序中的各个函数会被加载存放在虚拟地址空间中的代码段。</p><p> 代码段中指令的执行流程：<br>    - 顺序指令：每个进程只会执行一次<br>    - 循环指令：需要使用跳转指令返回函数的头部<br>    - 递归指令：需要借助栈来实现</p><p>代码段指令由 <code>操作码：操作对象</code> 构成。</p><ul><li>操作码通常包括 <code>MOV</code>， <code>PUSH</code>，<code>POP</code>,<code>XCHG</code></li><li>操作对象可以是<ul><li>立即数： 比如golang中某一段程序 <code>x := 1 + 1</code>， 其中的1就是立即数，它不会被储存在任意寄存器中，它直接包含在代码里。</li><li>局部数据：也就是局部变量，它将在栈区分配空间，代码段会引用该数据地址</li><li>BSS数据与数据段数据：与上同，关于BSS，数据段将在下面详细说明。</li></ul></li></ul><h2 id="数据段"><a href="#数据段" class="headerlink" title="数据段"></a>数据段</h2><p>数据段一般存放<code>已初始化</code>且<code>初值不为0</code>的全局变量和静态局部变量。数据段属于静态内存分配。</p><h2 id="BSS-段"><a href="#BSS-段" class="headerlink" title="BSS 段"></a>BSS 段</h2><p>有些地方可能会和数据段合并，将数据段划分为初始化区和未初始化区。</p><p>未初始化或者初值为0的全局变量和静态局部变量</p><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><p>动态分配的内存。</p><p>在go中，我们使用 <code>make</code>, <code>new</code>来分配的就在堆中开辟。这部分的内存可以最终由 GC回收。</p><h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><p>局部变量，函数参数，返回地址等等</p>]]></content>
      
      
      <categories>
          
          <category> 内存 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 内存 </tag>
            
            <tag> 操作系统 </tag>
            
            <tag> 汇编 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅析golang 闭包</title>
      <link href="2021/06/03/%E6%B5%85%E6%9E%90golang-%E9%97%AD%E5%8C%85/"/>
      <url>2021/06/03/%E6%B5%85%E6%9E%90golang-%E9%97%AD%E5%8C%85/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是闭包"><a href="#什么是闭包" class="headerlink" title="什么是闭包"></a>什么是闭包</h1><pre><code>闭包包含自由变量（在函数外部定义，但在函数内被引用），闭包的自由变量在被捕捉时被确定，保证脱离了捕捉时的上下文也能照常运行。    --- 摘自维基百科</code></pre>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 闭包 </tag>
            
            <tag> 计算机科学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 相关场景</title>
      <link href="2021/06/01/Redis-%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/"/>
      <url>2021/06/01/Redis-%E6%B7%B1%E5%85%A5%E6%8E%A2%E8%AE%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis-使用的基本使用场景"><a href="#Redis-使用的基本使用场景" class="headerlink" title="Redis 使用的基本使用场景"></a>Redis 使用的基本使用场景</h1><p><img src="https://i.loli.net/2021/06/04/5Xs86n1NctQjK3e.png" alt="redis.png"></p><h1 id="Redis-与-数据库数据的一致性问题"><a href="#Redis-与-数据库数据的一致性问题" class="headerlink" title="Redis 与 数据库数据的一致性问题"></a>Redis 与 数据库数据的一致性问题</h1><h2 id="抛出问题"><a href="#抛出问题" class="headerlink" title="抛出问题"></a>抛出问题</h2><pre><code>    当对数据进行修改时，应该先删除缓存还是先写入数据库中？</code></pre><h3 id="（方案一）-先删缓存，-后写数据库。"><a href="#（方案一）-先删缓存，-后写数据库。" class="headerlink" title="（方案一） 先删缓存， 后写数据库。"></a>（方案一） 先删缓存， 后写数据库。</h3><ul><li>在高并发的场景下，线程1删除缓存，还未写入数据时，线程2开始读数据，它会读到一个nil，并从数据库中读旧数据, 线程2开始更新缓存。此时，线程1数据成功写入，并更新了缓存，之后线程2将旧数据覆盖了线程1写入的新数据。这就造成了数据不一致 <code>（cache old : db new)</code></li></ul><table><thead><tr><th></th><th>Thread1</th><th>Thread2</th></tr></thead><tbody><tr><td>t1</td><td>delete cache</td><td></td></tr><tr><td>t2</td><td></td><td>read -&gt; (cache)nil -&gt;（DB）old data</td></tr><tr><td>t3</td><td>write DB -&gt; update cache</td><td></td></tr><tr><td>t4</td><td></td><td>write cache (overwrite)</td></tr></tbody></table><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ul><li><ol><li>不删除缓存，而是将缓存改成一个特殊值（比如 <code>locking</code>）。在客户端的设计上，读到该特殊值，就休眠一会，再查Redis</li></ol><ul><li>缺陷：</li><li><ol><li>特殊值对业务的侵入。（必须挑选一个与业务严格无关的值）</li></ol></li><li><ol start="2"><li>休眠时间可能重复，降低性能。</li></ol></li></ul></li><li><ol start="2"><li>延时双删。 删缓存 -&gt; 写数据库 -&gt; 休眠一会 -&gt; 删除缓存</li></ol><ul><li>缺陷</li><li>1.写操作频繁的场景下，仍然无法避免脏数据。</li></ul></li></ul><p>不能在写操作频繁的情况下使用</p><h3 id="（方案二）先写数据，再删缓存"><a href="#（方案二）先写数据，再删缓存" class="headerlink" title="（方案二）先写数据，再删缓存"></a>（方案二）先写数据，再删缓存</h3><ul><li>数据库写完后，缓存删除失败，数据就会不一致。</li></ul><h4 id="解决方案："><a href="#解决方案：" class="headerlink" title="解决方案："></a>解决方案：</h4><ul><li><ol><li>给缓存设置过期时间。</li></ol><ul><li>缺陷</li><li>过期时间内，缓存数据未更新，仍有脏数据风险。</li></ul></li><li><ol start="2"><li>引入MQ, 保证原子性， 删除缓存失败，会重试</li></ol><ul><li>缺陷</li><li>重试时间内，仍然存在脏数据。</li></ul></li><li><ol start="3"><li>业务不再处理脏数据的问题。业务层只需要给value设置一个逻辑过期时间。另开一个线程，用来扫描缓存，并删除过期的缓存。</li></ol></li></ul><p>只能保证最终一致性，而不能保证实时一致。</p><h1 id="Redis-缓存穿透"><a href="#Redis-缓存穿透" class="headerlink" title="Redis 缓存穿透"></a>Redis 缓存穿透</h1><p>缓存中查不到，数据库中也查不到。(不断地去查数据库中不存在的数据。)</p><ul><li>解决方案<ol><li>对参数进行合法性校验</li><li>将查询不到的数据写入数据库。（Redis会记录很多无效key.可以将不合法数据过期时间设置短一点。）</li><li>引入布隆过滤器（BloomFilter），访问Redis前，数据是否存在。布隆过滤器存在一定误判率，且只能加数据，不能减</li></ol></li></ul><h1 id="Redis-缓存击穿"><a href="#Redis-缓存击穿" class="headerlink" title="Redis 缓存击穿"></a>Redis 缓存击穿</h1><p>缓存中没有数据，但是数据库中有数据。（缓存数据初始化，或者key过期。 ）</p><p>高并发场景下，过期key写入缓存的延时中，出现大量访问该key的线程，由于缓存中不存在该key。数据库将承受巨大压力。</p><ul><li>解决方案<ol><li>热点缓存永不过期。但是要注意value需要有逻辑过期时间。在另一个线程定期更新该数据。（对系统存在损耗）</li><li>避免DB承受并发压力：DB给redis写入key时，加锁，让访问该key的线程等待，避免压力击穿redis到DB上<h1 id="Redis-缓存雪崩"><a href="#Redis-缓存雪崩" class="headerlink" title="Redis 缓存雪崩"></a>Redis 缓存雪崩</h1></li></ol></li></ul><p>缓存大面积过期，请求全部转发到DB。</p><ul><li>解决方案：<ol><li>将缓存过期时间分散开。 在原有的统一的过期时间基础上，增加随机值。</li><li>对于分布式系统，可以将热点数据分散到不同节点上。</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> nosql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nosql </tag>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis</title>
      <link href="2021/06/01/Redis/"/>
      <url>2021/06/01/Redis/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><h2 id="Redis-简介"><a href="#Redis-简介" class="headerlink" title="Redis 简介"></a>Redis 简介</h2><p>Redis 全称 (REmote DIctionary Serer) 远程字典服务， 是一个键值对数据库。</p><p>与 NoSQL 相对应的 关系型数据库在当今环境存在的问题：</p><ul><li>性能： 磁盘IO性能低</li><li>扩展： 数据之间的关系复杂，扩展性差，不便于大规模集群使用</li></ul><p>NoSQL对其缺点进行了改进：</p><ul><li>内存存储</li><li>不存数据关系，只存数据</li></ul><h2 id="Redis-的特征"><a href="#Redis-的特征" class="headerlink" title="Redis 的特征"></a>Redis 的特征</h2><ol><li>数据之间没有必然联系</li><li>采用单线程机制</li><li>高性能。 </li><li>多数据类型：<ul><li>string</li><li>list</li><li>hash</li><li>set</li><li>sorted_set</li></ul></li></ol><ul><li>持久化。数据灾难恢复。</li></ul><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul><li>热点数据加速查询</li><li>任务队列</li><li>实时信息</li><li>时效信息</li><li>分布式数据功效。分布式集群中的session分离</li><li>消息队列</li><li>分布式锁</li></ul><h2 id="Redis-的一些功能"><a href="#Redis-的一些功能" class="headerlink" title="Redis 的一些功能"></a>Redis 的一些功能</h2><ul><li>缓存<ul><li>针对一些高并发业务的设计</li><li>平台的高频率数据。</li></ul></li><li>单服务器升级集群</li><li>Session 管理</li><li>Token</li></ul><h2 id="Redis-命令"><a href="#Redis-命令" class="headerlink" title="Redis 命令"></a>Redis 命令</h2><h3 id="单值缓存"><a href="#单值缓存" class="headerlink" title="单值缓存"></a>单值缓存</h3><ul><li>写 <code>set [key] [value]</code></li><li>读 <code>get [key] ([value])</code> 。 如果取的值不存在，返回 <code>(nil)</code></li></ul><h3 id="对象缓存"><a href="#对象缓存" class="headerlink" title="对象缓存"></a>对象缓存</h3><ul><li>SET user:1 value(json)</li><li>MSET user:1:name xxx user:1:balance xxx</li></ul>]]></content>
      
      
      <categories>
          
          <category> nosql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nosql </tag>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka</title>
      <link href="2021/05/30/kafka/"/>
      <url>2021/05/30/kafka/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是kafks"><a href="#什么是kafks" class="headerlink" title="什么是kafks"></a>什么是kafks</h1><p>kafka是一个分布式日志系统（也可以当作MQ系统）。</p><p>常用于：（日志收集系统，消息系统）</p><ul><li>web/nginx日志</li><li>访问日志</li><li>消息服务</li></ul><p>它具备的属性：</p><ul><li>分布式</li><li>分区</li><li>多副本</li><li>多订阅者</li></ul><p>它设计目标是：</p><ul><li>高效率：<ul><li>以时间复杂度为O(1)的方式提供消息持久化的能力， 即使TB级别的数据也能保证常数时间复杂度的访问性能。</li></ul></li><li>高吞吐：<ul><li>在廉价的商用机器上也能保证100k条/s的消息传输。</li></ul></li><li>分布式：<ul><li>支持Kafka Server 之间的消息分区，分布式消费。同时保证每个partition内消息顺序传输</li></ul></li><li>同时支持离线数据处理和实时数据处理</li><li>Scale out: 支持在线的水平拓展</li></ul><h2 id="所谓消息系统"><a href="#所谓消息系统" class="headerlink" title="所谓消息系统"></a>所谓消息系统</h2><p>消息系统负责将数据从一个应用传递到另外一个应用。应用不需要关心消息的传递方式，只需要关心消息的生产与消费。</p><p>分布式消息传递，基于可靠的消息队列，在客户端和消息系统之间异步传递消息。主流的消息传递模式有：</p><ul><li>点对点</li><li>发布-订阅 （观察者模式）</li></ul><p>Kafka使用的是后者。</p><h3 id="点对点"><a href="#点对点" class="headerlink" title="点对点"></a>点对点</h3><p>所谓点对点传递，即在一个消息队列中，每条消息只能被消费一次，虽然一个消息队列有多个生产者和消费者在使用。这能保证数据的顺序。</p><p>tip：生产者发送一条消息，只有一个消费者能够收到。</p><h3 id="发布-订阅"><a href="#发布-订阅" class="headerlink" title="发布-订阅"></a>发布-订阅</h3><p>在这个模式中，消息不再存放在队列中，而是一个 <code>Topic</code>。且消费者可以订阅多个topic，且消费者可以消费订阅的topic中的数据。并且一条数据被一个消费者消费后并不会被马上删除，而还能被另外的消费者消费。</p><p>在这个模式下，生产者被叫做发布者，消费者被叫做订阅者。</p><p>tip：发布者发送消息到topic，所有且只有订阅了该topic的订阅者都会收到消息。</p><h1 id="Kafka的优点"><a href="#Kafka的优点" class="headerlink" title="Kafka的优点"></a>Kafka的优点</h1><ul><li>解耦 / 扩展<ul><li>消息系统在处理过程中插入了一个接口层。发布者和订阅者都需要实现这个接口。这就意味着，双方都可以扩展或修改处理过程代码。方便未来需求的增加与修改。</li></ul></li><li>副本<ul><li>将消息从队列中删除之前，需要保证消息已经处理完成。这是为了避免处理数据失败后，数据已经被删除导致的数据丢失引起的业务失败。</li></ul></li><li>灵活 / 峰值处理能力<ul><li>保证访问量剧增的情况下，系统仍然正常运行。</li></ul></li><li>恢复<ul><li>系统的一部分失效后，整个系统仍然正常运行。</li></ul></li><li>有序</li><li>缓冲<ul><li>当一个系统中有需要处理的时间不同的消息。系统通过缓冲层保证消息以最高效率执行。</li></ul></li><li>异步通信<ul><li>允许消息放入队列，而不立即处理，等需要时再去处理。</li></ul></li></ul><h1 id="Kafka的劣势"><a href="#Kafka的劣势" class="headerlink" title="Kafka的劣势"></a>Kafka的劣势</h1><ul><li>对于整个系统来说，对Kafka的依赖过高，一旦Kafka宕机，整个系统也崩溃了。所以需要保证其高可用</li><li>提高了系统复杂度。从系统间同步远程调用，到现在的异步调用，需要保证消息不丢失。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> 消息系统 </tag>
            
            <tag> 中间件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GC</title>
      <link href="2021/05/30/GC/"/>
      <url>2021/05/30/GC/</url>
      
        <content type="html"><![CDATA[<h1 id="golang-的GC"><a href="#golang-的GC" class="headerlink" title="golang 的GC"></a>golang 的GC</h1><ul><li>垃圾回收</li><li>内存管理</li><li>自动释放</li><li>三色标记法</li><li>STW(stop the world)</li></ul><h2 id="（一）-标记清除法-golang-v1-3"><a href="#（一）-标记清除法-golang-v1-3" class="headerlink" title="（一） 标记清除法 (golang v1.3)"></a>（一） 标记清除法 (golang v1.3)</h2><ol><li>STW，暂停程序业务逻辑， 找到可达对象和不可达对象</li><li>标记可达对象</li><li>清除不可达对象</li><li>程序恢复</li></ol><p>循环以上过程，直到程序生命周期结束</p><p><img src="https://i.loli.net/2021/05/30/pWJZUxQDvF6Vsct.png" alt="markAndSweep.png"></p><ul><li>缺点<ul><li>STW 暂停程序，出现卡顿 (严重)<ul><li>后期将 <code>sweep清除</code> 移出STW 暂停范围</li></ul></li><li>需要扫描整个heap</li><li>清除数据会产生heap碎片。</li></ul></li></ul><h2 id="（二）三色标记（golang-v1-4）"><a href="#（二）三色标记（golang-v1-4）" class="headerlink" title="（二）三色标记（golang v1.4）"></a>（二）三色标记（golang v1.4）</h2><ol><li>程序开始创建的对象均标记为白色。</li><li>每次GC开始时，从根节点遍历所有对象，把遍历到的对象从白色集合转移到灰色集合。</li><li>遍历灰色集合，将灰色集合中的对象所引用的对象从白色集合放入灰色集合，并将此灰色对象移入黑色对象。</li><li>重复上述步骤，直至灰色列表中没有任何对象。</li><li>回收所有的白色列表中的对象。</li></ol><ul><li><p>三色标记法会出现的严重问题</p><ul><li><p>条件1 黑色对象引用了一个白色对象。</p></li><li><p>条件2 同时，该白色对象原本可由其他灰色对象引用，但该引用遭到了破坏。</p></li><li><p>满足以上两个条件，会导致一个不是垃圾的白色对象，因为被黑色对象引用，无法转成灰色对象，最后被回收，这就叫做 <code>对象丢失</code></p></li></ul></li></ul><h3 id="三色不变式"><a href="#三色不变式" class="headerlink" title="三色不变式"></a>三色不变式</h3><ul><li>强三色不变式<ul><li>强制性不允许黑色对象引用白色对象 （ 破坏条件1）</li></ul></li><li>弱三色不变式<ul><li>黑色可以引用白色对象，但该白色对象必须存在一个灰色对象引用它(或该白色对象必须是可达对象) （破坏条件2</li></ul></li></ul><h2 id="三-屏障机制"><a href="#三-屏障机制" class="headerlink" title="(三) 屏障机制"></a>(三) 屏障机制</h2><h3 id="什么叫屏障"><a href="#什么叫屏障" class="headerlink" title="什么叫屏障"></a>什么叫屏障</h3><p>屏障是一个额外的判断机制</p><p>类似下面三种概念</p><ul><li><p>Hook</p></li><li><p>回调</p></li><li><p>handler</p></li><li><p>插入机制</p><ul><li>对象被引用时触发的机制</li></ul></li><li><p>删除屏障</p><ul><li>对象被删除时触发的机制</li></ul></li></ul><h3 id="插入屏障-（不用于栈）"><a href="#插入屏障-（不用于栈）" class="headerlink" title="插入屏障 （不用于栈）"></a>插入屏障 （不用于栈）</h3><ul><li>在A对象引用B对象时，B对象被标记为灰色。（满足：强三色不变式）</li><li>不足： 因为不希望插入写屏障影响栈空间的效率，它不会应用于栈空间。因此，为了避免栈空间出现 <code>对象丢失</code>，我们在结束时（回收对象前）STW并扫描栈空间，这需要花费10 - 100 ms</li></ul><h3 id="删除屏障"><a href="#删除屏障" class="headerlink" title="删除屏障"></a>删除屏障</h3><ul><li>被删除的对象，如果自身为灰色或者白色，都标记为灰色。<br>（换句话说，当要断开一个灰色对象引用一个白色对象之间的通路时，将该白色对象变灰，避免当其他黑色对象引用这个白色对象时，因为灰色对象的断开导致这个白色对象 <code>对象丢失</code>）</li><li>不足：<ul><li>回收精度低，当灰色对象和白色对象断开引用时，该应该被删除的白色对象在这轮GC时最终被标记为黑色，活过了这轮GC</li></ul></li></ul><h3 id="混合写屏障"><a href="#混合写屏障" class="headerlink" title="混合写屏障"></a>混合写屏障</h3><ul><li>GC开始时，栈上的对象全部扫描并标记为黑色（解决了插入屏障栈空间二次扫描和STW问题） <code>这会不会导致内存泄露？</code></li><li>GC期间，栈上创建的新对象均为黑色的。</li><li>[堆] 被删除的对象被标记为灰色</li><li>[堆] 被添加的对象标记为灰色</li></ul><p>这是一个变形的弱三色不变式，结合了插入、删除写屏障两者的优点</p><h1 id="场景分析"><a href="#场景分析" class="headerlink" title="场景分析"></a>场景分析</h1><h2 id="场景1"><a href="#场景1" class="headerlink" title="场景1"></a>场景1</h2><p>一个对象被堆对象删除，并成为了栈对象的下游对象。</p><p>堆中由于开启了混合写屏障，我们要删除该对象，需要先扫描到它的上游对象，并将上游对象标灰。删除该对象后，该对象会变灰，之后又被栈对象引用，成为一个栈对象。</p><h2 id="场景2"><a href="#场景2" class="headerlink" title="场景2"></a>场景2</h2><p>对象被栈对象删除引用， 并成为另一个栈对象下游</p><p>栈空间不启用屏障，该场景的对象一直都是黑色对象</p><h2 id="场景3"><a href="#场景3" class="headerlink" title="场景3"></a>场景3</h2><p>对象被堆对象删除引用， 并成为另一个堆对象下游</p><p>一个黑色堆对象，引用一个灰色堆对象A的下游白对象，白对象B因为写屏障被标记灰色，同时它的上游对象A断开和它的引用。</p><h2 id="场景4"><a href="#场景4" class="headerlink" title="场景4"></a>场景4</h2><p>一个对象从栈对象被删除引用，并成为了另一个堆对象的下游</p><p>该对象仍然为黑，另一个堆对象的原下游对象A本来还是白色的，由于屏障机制，变成灰色，如果该对象成了游离对象，它只会在下轮被回收。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> gc </tag>
            
            <tag> 三色标记法 </tag>
            
            <tag> 写屏障 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 的网络I/O复用并发模型</title>
      <link href="2021/05/29/Linux-%E7%9A%84%E7%BD%91%E7%BB%9CI-O%E5%A4%8D%E7%94%A8%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/"/>
      <url>2021/05/29/Linux-%E7%9A%84%E7%BD%91%E7%BB%9CI-O%E5%A4%8D%E7%94%A8%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-中网络I-O复用并发模型"><a href="#Linux-中网络I-O复用并发模型" class="headerlink" title="Linux 中网络I/O复用并发模型"></a>Linux 中网络I/O复用并发模型</h1><h2 id="什么是阻塞，非阻塞，IO多路复用？"><a href="#什么是阻塞，非阻塞，IO多路复用？" class="headerlink" title="什么是阻塞，非阻塞，IO多路复用？"></a>什么是阻塞，非阻塞，IO多路复用？</h2><ul><li><p>流</p><ul><li>可进行I/O操作的内核对象<ul><li>文字</li><li>管道</li><li>套接字</li></ul></li><li>流的入口：文件描述符(fd)</li></ul></li><li><p>阻塞等待<br>不占用CPU时间片</p><ul><li>缺点<ul><li>不能处理多个I/O请求的问题</li><li>同一个阻塞，同一时间只能处理一个流的阻塞监听</li></ul></li></ul></li><li><p>非阻塞（忙轮询）<br>占用资源不断去查看资源锁有没有释放</p></li><li><p>多路IO复用<br>既能阻塞等待，不浪费资源，又能同一时刻监听多个IO请求的状态</p></li></ul><h2 id="IO复用解决的问题"><a href="#IO复用解决的问题" class="headerlink" title="IO复用解决的问题"></a>IO复用解决的问题</h2><p>如何解决大量IO读写问题</p><ul><li>忙轮询</li></ul><pre><code>while true &#123;    for i in 流[] &#123;        if i has 数据 &#123;            读 或者 其他处理        &#125;    &#125;&#125;</code></pre><p>同时和多个流访问。</p><ul><li>select</li></ul><pre><code>while true &#123;    select(流[]); //阻塞  //有消息抵达    for i in 流[] &#123;        if i has 数据 &#123;            读 或者 其他处理        &#125;    &#125;&#125;</code></pre><p>select负责接收IO，但不能精准直到哪些IO可用，还需要遍历。监听的IO有限，一般1024个，与平台无关</p><ul><li>epoll</li></ul><pre><code>while true &#123;    可处理的流[] = epoll_wait(epoll_fd); //阻塞  //有消息抵达，全部放在 “可处理的流[]”中    for i in 可处理的流[] &#123;        读 或者 其他处理    &#125;&#125;</code></pre><p>类似select,但能返回所有可以处理的流，不必再去遍历确认</p><h2 id="epoll是什么"><a href="#epoll是什么" class="headerlink" title="epoll是什么"></a>epoll是什么</h2><ul><li>linux独有</li><li>一种I/O 多路复用技术</li><li>只关心活跃的链接，无需遍历所有的描述符集合。</li><li>能处理大量链接请求（系统可以打开的文件数目 <code>cat /proc/sys/fs/file-max</code>）</li></ul><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><ol><li>创建</li></ol><pre><code>/**  * @param size 告诉内核监听的数目  *  * @returns 返回一个epoll句柄（即一个文件描述符）  */int epoll_create(int size);</code></pre><ol start="2"><li>控制</li></ol><pre><code>/*** @param epfd 用epoll_create所创建的epoll句柄* @param op 表示对epoll监控描述符控制的动作** EPOLL_CTL_ADD(注册新的fd到epfd)* EPOLL_CTL_MOD(修改已经注册的fd的监听事件)* EPOLL_CTL_DEL(epfd删除一个fd)** @param fd 需要监听的文件描述符* @param event 告诉内核需要监听的事件** @returns 成功返回0，失败返回-1, errno查看错误信息*/int epoll_ctl(int epfd, int op, int fd,struct epoll_event *event);struct epoll_event &#123;    __uint32_t events; /* epoll 事件 */    epoll_data_t data; /* 用户传递的数据 */&#125;/* * events : &#123;EPOLLIN, EPOLLOUT, EPOLLPRI,                         EPOLLHUP, EPOLLET, EPOLLONESHOT&#125; */typedef union epoll_data &#123;    void *ptr;    int fd;    uint32_t u32;    uint64_t u64;&#125; epoll_data_t;</code></pre><ol start="3"><li>等待</li></ol><pre><code>/**** @param epfd 用epoll_create所创建的epoll句柄* @param event 从内核得到的事件集合* @param maxevents 告知内核这个events有多大,* 注意: 值 不能大于创建epoll_create()时的size.* @param timeout 超时时间* -1: 永久阻塞* 0: 立即返回，非阻塞* &gt;0: 指定微秒** @returns 成功: 有多少文件描述符就绪,时间到时返回0* 失败: -1, errno 查看错误*/int epoll_wait(int epfd, struct epoll_event *event,                             int maxevents, int timeout);</code></pre><h3 id="epoll-基本编程架构"><a href="#epoll-基本编程架构" class="headerlink" title="epoll 基本编程架构"></a>epoll 基本编程架构</h3><pre><code>int epfd = epoll_crete(1000);//将 listen_fd 添加进 epoll 中epoll_ctl(epfd, EPOLL_CTL_ADD, listen_fd,&amp;listen_event);while (1) &#123;    //阻塞等待 epoll 中 的fd 触发    int active_cnt = epoll_wait(epfd, events, 1000, -1);    for (i = 0 ; i &lt; active_cnt; i++) &#123;        if (evnets[i].data.fd == listen_fd) &#123;            //accept. 并且将新accept 的fd 加进epoll中.        &#125;        else if (events[i].events &amp; EPOLLIN) &#123;            //对此fd 进行读操作        &#125;        else if (events[i].events &amp; EPOLLOUT) &#123;            //对此fd 进行写操作        &#125;    &#125;&#125;</code></pre><h2 id="常见模型"><a href="#常见模型" class="headerlink" title="常见模型"></a>常见模型</h2><h3 id="单线程Accept"><a href="#单线程Accept" class="headerlink" title="单线程Accept"></a>单线程Accept</h3><p><img src="https://i.loli.net/2021/05/29/QHCbulfpiFw8Yx5.png" alt="single-accept.png"></p><ul><li>主线程的 <code>Accept（ListenFd）</code> 会阻塞主线程</li><li>连接成功后，会在服务端生成一个连接的套接字</li><li>一次只能形成一个连接，另一个客户端如果尝试连接，会阻塞</li><li>处理完当前客户端，并关闭套接字文件，再去处理下一个客户端</li></ul><h3 id="单线程Accept-多线程读写业务-无I-O复用"><a href="#单线程Accept-多线程读写业务-无I-O复用" class="headerlink" title="单线程Accept + 多线程读写业务 (无I/O复用)"></a>单线程Accept + 多线程读写业务 (无I/O复用)</h3><p><img src="https://i.loli.net/2021/05/29/xTDhEHmgX3cYdvS.png" alt="single_multiple-thread.png"></p><ul><li><code>Accept(ListenFd)</code> 监听客户端请求，阻塞主线程</li><li>接收客户端请求后，开辟一个新线程，进行读写业务。</li><li>主线程继续监听，能处理其他客户端的请求</li></ul><p>这个模型虽然支持了并发，但是：</p><ul><li>高并发情况下，多线程加重服务器负担</li><li>长连接的场景，客户端没有读写业务，但它不关闭，就需要不断进行心跳检测，占用了资源。</li></ul><h3 id="单线程多路I-O复用"><a href="#单线程多路I-O复用" class="headerlink" title="单线程多路I/O复用"></a>单线程多路I/O复用</h3><p><img src="https://i.loli.net/2021/05/29/jR7IJpbGqB58x6s.png" alt="single-reuseIO.png"></p><ul><li>主线程创建 <code>listenFd</code>， 采用多路I/O服用机制，进行IO状态阻塞监控。当client1发送请求，检测到了 <code>listenFd</code> 触发读时间，运行 accept 建立连接，并将 <code>connFd1</code>加入监听集合。</li><li>client1进行读写请求时，多路IO复用机制的监听阻塞释放，并触发套接字读写事件</li><li>client1触发的读写业务会使主线程阻塞，无法处理新的客户端的请求。</li></ul><p>该模型可以监听多个客户端的读写状态。且发生阻塞，处于非忙轮询的状态，不浪费CPU资源</p><p><strong>缺点</strong>：</p><ul><li>能同时监听，但不能同时处理多个客户端的读写请求</li><li>不支持高并发场景</li></ul><h2 id="单线程多路I-O复用-多线程业务工作池"><a href="#单线程多路I-O复用-多线程业务工作池" class="headerlink" title="单线程多路I/O复用 + 多线程业务工作池"></a>单线程多路I/O复用 + 多线程业务工作池</h2><p>该场景使用比较少</p><p><img src="https://i.loli.net/2021/05/29/yLX8YB1SvKU9s5M.png" alt="single-reuse-thread.png"></p><ul><li>主线程采用多路I/O复用机制监听连接请求。当监听到客户端连接请求后，处理连接请求，并将生成的<code>connFd1</code>加入到监听集合中</li><li>当监听到读写事件，则进行读写消息的处理</li><li>主线程处理读写消息，将业务逻辑交给工作线程池处理。工作线程池在server启动前开启的一定数量的线程。他们只处理逻辑业务，不处理套接字读写操作。</li><li>工作线程池处理完业务，再触发<code>connFd1</code>的写事件，将回执消息返回给对方</li></ul><p>优点：<br>    - 将业务处理分离出来，缩短客户端的等待时间。<br>    - 能并发处理客户端业务。</p><p>缺点：<br>    - 读写处理仍然需要单独处理。(排队)<br>    - 业务处理后的结果，也需要按顺序返回给客户端。（排队）</p>]]></content>
      
      
      <categories>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> 并发模型 </tag>
            
            <tag> epoll </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>first blood</title>
      <link href="2021/05/28/first-blood/"/>
      <url>2021/05/28/first-blood/</url>
      
        <content type="html"><![CDATA[<h1 id="0-初次见面"><a href="#0-初次见面" class="headerlink" title="0.初次见面"></a>0.初次见面</h1><p>拖延症患者，拖拖拉拉，终于开始搭建自己的博客。本博客使用 <code>Hexo</code> 和 <code>Github page</code> 。下面是博客搭建的历程。</p><h1 id="1-准备环境"><a href="#1-准备环境" class="headerlink" title="1.准备环境"></a>1.准备环境</h1><ul><li><a href="https://nodejs.org/en/">NodeJS</a> </li><li>git</li></ul><h1 id="2-安装Hexo"><a href="#2-安装Hexo" class="headerlink" title="2.安装Hexo"></a>2.安装Hexo</h1><p><a href="https://hexo.io/zh-cn/">Hexo官网</a></p><p><code>npm</code> 是NodeJS的包管理工具，关于Hexo的安装或者依赖的下载都可以交给它完成</p><p><code>npm install -g hexo-cli</code></p><p>安装完成后执行以下命令</p><pre><code>hexo init myBlogcd myBlognpm install</code></pre><h2 id="测试hexo"><a href="#测试hexo" class="headerlink" title="测试hexo"></a>测试hexo</h2><pre><code>hexo s</code></pre><p>访问<code>http://localhost:4040</code>可以预览博客效果。</p><h1 id="3-Github-Page-部署"><a href="#3-Github-Page-部署" class="headerlink" title="3.Github Page 部署"></a>3.Github Page 部署</h1><ul><li><p>新建仓库</p><ul><li>注意仓库名严格按照<code>[用户名].github.io</code>命名</li></ul></li><li><p>SSH key 配置</p><pre><code>git config --global user.name &quot;用户名&quot;git config --global user.email &quot;邮箱地址&quot;ssh-keygen -t rsa -C &#39;上面的邮箱&#39;cat ~/.ssh/id_rsa.pub</code></pre></li><li><p>将生成密钥添加到 Github 上</p><ul><li><code>settings -&gt; SSH and GPG keys -&gt; New SSH key</code></li></ul></li><li><p>本地部署到Github</p><ul><li>博客目录下 <code>_config.yml</code>,在文件末尾添加：<pre><code>deploy:type: gitrepo:    github: https://github.com/Jiaget/Jiaget.github.io.git,main</code></pre></li><li>安装部署插件 <code>npm install hexo-deployer-git --save</code></li><li>博客页面生成与上传 <code>hexo g -d</code></li></ul></li><li><p>上传到github到最后效果的显示有段时间延迟，访问 <code> https://你的用户名.github.io</code>就能看到自己的博客了。</p></li></ul><h1 id="4-写作"><a href="#4-写作" class="headerlink" title="4.写作"></a>4.写作</h1><ul><li><p>新建文章 <code>hexo new &#39;文章标题&#39;</code></p><ul><li>文章会生成在 <code>/source/_posts</code> 下</li></ul></li><li><p>执行 </p><pre><code>hexo ghexo s</code></pre><p>文章在博客中显示</p></li><li><p>部署</p><pre><code>hexo cleanhexo g -d</code></pre><p><code>hexo clean </code> 是为了清除缓存文件<code>db.json</code>以及静态文件<code>public</code>。</p></li><li><p>写好的文章暂时不想发布，可以存在草稿里，草稿的生成方法 <code>exo new draft &quot;文章标题&quot;</code></p><ul><li>草稿保存在<code>/source/_drafts</code>中，需要发布只需要<code>hexo publicsh [layout]&lt;filename&gt;</code></li></ul></li></ul><h2 id="git-源码管理"><a href="#git-源码管理" class="headerlink" title="git 源码管理"></a>git 源码管理</h2><p>hexo会把<code>./deploy_git</code>中的静态页面上传给github, 也就是说我们写的markdown文件以及hexo源码都在本地储存。</p><p>因此我们还需要将源码托管到github。不需要新建仓库，只需要新的分支管理即可。</p><p>关于分支，这里需要提一句，在 <code>github page</code> 部署的静态页面应该在 <code>main</code> 分支，而不是 <code>master</code>分支。github应该是将主分支名称修改了，原先一直是 <code>master</code>。</p><ul><li><p>将本地源码和 github 仓库连接 <code>git remote add origin git@github.com:Jiaget/Jiaget.github.io.git</code></p></li><li><p>检查 <code>.gitignore</code>, 忽视无关文件。如果没有该文件，则新建一个。</p></li></ul><pre><code>.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/</code></pre><p>最后推送给新的分支</p><pre><code>git add .git commit -m &quot;hexo source code&quot;git push origin master:source</code></pre>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>categories</title>
      <link href="2021/05/28/categories/"/>
      <url>2021/05/28/categories/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
